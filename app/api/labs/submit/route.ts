import { createClient } from '@supabase/supabase-js'
import { NextResponse } from 'next/server'
import { scoreGitHubRepo } from '@/lib/github-scorer'

const supabaseAdmin = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
)

// Anti-cheat patterns to detect in code
const AI_PATTERNS = [
  /\/\/ generated by (chatgpt|copilot|ai|gpt|claude|gemini)/i,
  /\/\*\s*(auto-generated|ai-generated)\s*\*\//i,
  /this code was (generated|written) (by|using) (ai|chatgpt|copilot)/i,
]

const PLAGIARISM_INDICATORS = [
  'lorem ipsum',
  'todo: implement',
  'insert code here',
  'your code goes here',
]

function runAntiCheatCheck(code: string): { flagged: boolean; reasons: string[] } {
  const reasons: string[] = []

  // Check for AI-generated patterns
  for (const pattern of AI_PATTERNS) {
    if (pattern.test(code)) {
      reasons.push('Code contains AI-generation markers')
      break
    }
  }

  // Check for placeholder/copy-paste indicators
  for (const indicator of PLAGIARISM_INDICATORS) {
    if (code.toLowerCase().includes(indicator)) {
      reasons.push(`Code contains placeholder text: "${indicator}"`)
    }
  }

  // Check for suspiciously perfect formatting with no personal style
  const lines = code.split('\n')
  const commentRatio = lines.filter(l => l.trim().startsWith('//')).length / Math.max(lines.length, 1)
  if (commentRatio > 0.4) {
    reasons.push('Unusually high comment-to-code ratio (possible AI generation)')
  }

  // Check for identical variable naming patterns common in AI
  const genericVarPattern = /const (result|data|response|output|value)\d?\s*=/g
  const matches = code.match(genericVarPattern)
  if (matches && matches.length > 5) {
    reasons.push('Repetitive generic variable naming pattern detected')
  }

  return { flagged: reasons.length > 0, reasons }
}

function scoreLabCode(code: string, instructions: string): { score: number; feedback: string } {
  let score = 0
  const feedbackPoints: string[] = []

  // 1. Code exists and has substance (20 points)
  const lineCount = code.split('\n').filter(l => l.trim()).length
  if (lineCount > 5) { score += 10; feedbackPoints.push('Code has meaningful content (+10)') }
  if (lineCount > 20) { score += 10; feedbackPoints.push('Code has good depth (+10)') }

  // 2. Follows instructions - keyword matching (30 points)
  const instructionKeywords = instructions.toLowerCase()
    .replace(/[^a-z0-9\s]/g, '')
    .split(/\s+/)
    .filter(w => w.length > 4)
    .filter((w, i, a) => a.indexOf(w) === i)
    .slice(0, 15)

  let keywordMatches = 0
  for (const kw of instructionKeywords) {
    if (code.toLowerCase().includes(kw)) keywordMatches++
  }
  const keywordScore = instructionKeywords.length > 0
    ? Math.round((keywordMatches / instructionKeywords.length) * 30)
    : 15
  score += keywordScore
  feedbackPoints.push(`Instruction keywords matched: ${keywordMatches}/${instructionKeywords.length} (+${keywordScore})`)

  // 3. Code quality indicators (20 points)
  if (/function\s+\w+|const\s+\w+\s*=\s*(\(|async)/.test(code)) {
    score += 10; feedbackPoints.push('Uses proper function definitions (+10)')
  }
  if (/try\s*{|\.catch\(|if\s*\(/.test(code)) {
    score += 5; feedbackPoints.push('Includes error handling/conditionals (+5)')
  }
  if (/import\s+|require\(|from\s+['"]/.test(code)) {
    score += 5; feedbackPoints.push('Uses module imports (+5)')
  }

  // 4. Code organization (20 points)
  if (/\/\/.*\w|\/\*[\s\S]*?\*\//.test(code)) {
    score += 10; feedbackPoints.push('Code is commented (+10)')
  }
  if (code.includes('\n\n')) {
    score += 5; feedbackPoints.push('Code uses proper spacing (+5)')
  }
  if (/class\s+\w+|interface\s+\w+|type\s+\w+/.test(code)) {
    score += 5; feedbackPoints.push('Uses structured types/classes (+5)')
  }

  // 5. Completeness bonus (10 points)
  if (lineCount > 50) {
    score += 5; feedbackPoints.push('Comprehensive implementation (+5)')
  }
  if (/export\s+(default\s+)?/.test(code)) {
    score += 5; feedbackPoints.push('Code exports properly (+5)')
  }

  score = Math.min(score, 100)

  const feedback = `Auto-graded score: ${score}/100\n\n` +
    feedbackPoints.join('\n') +
    (score >= 70 ? '\n\nGreat work! Your code meets the lab requirements.' :
     score >= 50 ? '\n\nGood effort. Review the instructions and improve your implementation.' :
     '\n\nNeeds improvement. Re-read the lab instructions and try again.')

  return { score, feedback }
}

export async function POST(req: Request) {
  const body = await req.json()
  const { lab_id, student_id, github_url, code, cheating_data } = body

  if (!lab_id || !student_id) {
    return NextResponse.json(
      { error: 'lab_id and student_id are required' },
      { status: 400 }
    )
  }

  if (!github_url && !code) {
    return NextResponse.json(
      { error: 'Either github_url or code is required' },
      { status: 400 }
    )
  }

  try {
    // Fetch lab details for scoring
    const { data: lab } = await supabaseAdmin
      .from('labs')
      .select('*, modules(week_number, course_id)')
      .eq('id', lab_id)
      .single()

    if (!lab) {
      return NextResponse.json({ error: 'Lab not found' }, { status: 404 })
    }

    // Check deadline from content_assignments
    let isLate = false
    let maxScorePercentage = 100
    const { data: assignment } = await supabaseAdmin
      .from('content_assignments')
      .select('*')
      .eq('content_type', 'lab')
      .eq('content_id', lab_id)
      .eq('student_id', student_id)
      .single()

    if (assignment) {
      const now = new Date()
      const deadline = assignment.deadline ? new Date(assignment.deadline) : null
      const graceDeadline = assignment.grace_deadline ? new Date(assignment.grace_deadline) : null

      if (graceDeadline && now > graceDeadline) {
        return NextResponse.json(
          { error: 'Submission deadline has passed. The grace period has expired.' },
          { status: 403 }
        )
      }

      if (deadline && now > deadline) {
        isLate = true
        maxScorePercentage = 60
      }
    }

    // Determine submission type and get code/score
    const isGitHub = !!github_url && !code
    let submittedCode = code || ''
    let githubScoreResult = null

    if (isGitHub) {
      // Extract keywords from lab instructions for GitHub scoring
      const instructionKeywords = (lab.instructions || '')
        .toLowerCase()
        .replace(/[^a-z0-9\s]/g, '')
        .split(/\s+/)
        .filter((w: string) => w.length > 4)
        .filter((w: string, i: number, a: string[]) => a.indexOf(w) === i)
        .slice(0, 15)

      githubScoreResult = await scoreGitHubRepo(github_url, instructionKeywords)
      submittedCode = github_url
    }

    // Run anti-cheat check on code content
    const cheatCheck = runAntiCheatCheck(submittedCode)

    // Also check sandbox behavioral data (large pastes, tab switches, rapid bursts)
    if (cheating_data) {
      if (cheating_data.largePastes > 2) {
        cheatCheck.flagged = true
        cheatCheck.reasons.push(`${cheating_data.largePastes} large paste events detected in sandbox`)
      }
      if (cheating_data.tabSwitches > 10) {
        cheatCheck.flagged = true
        cheatCheck.reasons.push(`${cheating_data.tabSwitches} tab switches detected (excessive)`)
      }
      if (cheating_data.rapidBursts > 3) {
        cheatCheck.flagged = true
        cheatCheck.reasons.push(`${cheating_data.rapidBursts} rapid typing bursts detected (possible automation)`)
      }
    }

    if (cheatCheck.flagged) {
      // Log anti-cheat event
      await supabaseAdmin.from('anti_cheat_events').insert({
        student_id,
        content_type: 'lab',
        content_id: lab_id,
        event_type: 'ai_detection',
        details: {
          reasons: cheatCheck.reasons,
          code_snippet: submittedCode.slice(0, 500),
          sandbox_data: cheating_data || null,
        },
      })
    }

    // Auto-score the lab
    let score: number
    let feedback: string

    if (isGitHub && githubScoreResult) {
      // Use GitHub auto-scoring bot result
      score = githubScoreResult.score
      feedback = `GitHub Repo Score: ${score}/100\n\n${githubScoreResult.feedback}\n\nBreakdown:\n` +
        `- Repo accessible: ${githubScoreResult.breakdown.repoExists}/10\n` +
        `- README present: ${githubScoreResult.breakdown.readmePresent}/10\n` +
        `- README quality: ${githubScoreResult.breakdown.readmeQuality}/10\n` +
        `- Relevant files: ${githubScoreResult.breakdown.relevantFiles}/20\n` +
        `- Code quality: ${githubScoreResult.breakdown.codeQuality}/20\n` +
        `- File structure: ${githubScoreResult.breakdown.fileStructure}/15\n` +
        `- Dependencies: ${githubScoreResult.breakdown.dependencies}/15`
    } else {
      const result = scoreLabCode(submittedCode, lab.instructions || '')
      score = result.score
      feedback = result.feedback
    }

    // Apply penalty if cheat flagged
    let finalScore = cheatCheck.flagged ? Math.max(0, score - 30) : score

    // Apply late penalty (60% max if in grace period)
    if (isLate) {
      finalScore = Math.round(finalScore * (maxScorePercentage / 100))
    }

    let finalFeedback = cheatCheck.flagged
      ? `WARNING: Potential integrity violation detected.\nReasons: ${cheatCheck.reasons.join(', ')}\nScore reduced by 30 points.\n\n${feedback}`
      : feedback

    if (isLate) {
      finalFeedback = `LATE SUBMISSION: Score capped at ${maxScorePercentage}% (grace period).\n\n${finalFeedback}`
    }

    // Scale score to lab total_points
    const scaledGrade = Math.round((finalScore / 100) * (lab.total_points || 100))

    // Check existing submission
    const { data: existing } = await supabaseAdmin
      .from('lab_submissions')
      .select('id')
      .eq('lab_id', lab_id)
      .eq('student_id', student_id)
      .order('submitted_at', { ascending: false })
      .limit(1)

    let submission
    const submissionData = {
      code: submittedCode,
      submitted_at: new Date().toISOString(),
      grade: scaledGrade,
      feedback: finalFeedback,
      graded_at: new Date().toISOString(),
      submission_type: isGitHub ? 'github' : 'sandbox',
      github_url: isGitHub ? github_url : null,
      is_late: isLate,
      max_score_percentage: maxScorePercentage,
      score_breakdown: isGitHub && githubScoreResult ? githubScoreResult.breakdown : null,
    }

    if (existing && existing.length > 0) {
      const { data, error } = await supabaseAdmin
        .from('lab_submissions')
        .update(submissionData)
        .eq('id', existing[0].id)
        .select()
        .single()
      if (error) throw error
      submission = data
    } else {
      const { data, error } = await supabaseAdmin
        .from('lab_submissions')
        .insert({ lab_id, student_id, ...submissionData })
        .select()
        .single()
      if (error) throw error
      submission = data
    }

    // Update daily progress
    if (lab.day_number && lab.modules) {
      await fetch(new URL('/api/progress', req.url).toString(), {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          student_id,
          course_id: lab.modules.course_id,
          module_id: lab.module_id,
          day_number: lab.day_number,
          lab_score: finalScore,
        }),
      })
    }

    return NextResponse.json({
      submission,
      score: finalScore,
      scaled_grade: scaledGrade,
      total_points: lab.total_points,
      feedback: finalFeedback,
      cheat_flagged: cheatCheck.flagged,
      cheat_reasons: cheatCheck.reasons,
      is_late: isLate,
      max_score_percentage: maxScorePercentage,
      submission_type: isGitHub ? 'github' : 'sandbox',
      github_score: isGitHub ? githubScoreResult : null,
    })
  } catch (err) {
    console.error('Lab submission error:', err)
    return NextResponse.json(
      { error: (err as Error).message || 'Failed to submit lab' },
      { status: 500 }
    )
  }
}
